{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da306d89-c20b-43c9-b0e8-adb960c35d5d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* Load required packages & set working directory\n",
    "* Function definitions\n",
    "* Data organization\n",
    "* Experiment 1 models\n",
    "* Experiment 1 SHAP plots\n",
    "* Experiment 2 models\n",
    "* Experiment 2 SHAP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbbdb7a-dbe5-429d-981e-cd94487c05ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from random import sample\n",
    "from itertools import chain\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # default is ‘last_expr’\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "#import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Set Working Directory #Make sure you're currently in the main repository folder.\n",
    "#os.chdir(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455004d8-0034-4709-905c-5969614a2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for recording model results and parameters\n",
    "\n",
    "def calculate_metrics_single(y_true, y_pred, duration, dataset, obs_col, model_name, model_run, smote,\n",
    "                             test_set, features_size, label_imb_train, label_imb_test, \n",
    "                             train_size, test_size):\n",
    "    res = pd.DataFrame(columns=['dataset', 'obs_col', 'model', 'model_run', 'smote', 'test-set',\n",
    "     'precision', 'recall', 'F1', 'accuracy', 'auc','avg_prec', 'feat.', 'label-imb-train', \n",
    "                                'label-imb-test', 'train-size', 'test-size', 'runtime(sec)'])\n",
    "    # AUROC\n",
    "    auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "    # AUPRC\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_true, y_pred)\n",
    "    avg_prec = metrics.auc(recall, precision)\n",
    "    \n",
    "    index_to_fill = res.shape[0]\n",
    "    res.loc[index_to_fill, 'dataset'] = dataset\n",
    "    res.loc[index_to_fill, 'obs_col'] = obs_col\n",
    "    res.loc[index_to_fill, 'model_run'] = model_run\n",
    "    #res.loc[index_to_fill, 'exp_type'] = exp_type\n",
    "    res.loc[index_to_fill, 'smote'] = smote\n",
    "    res.loc[index_to_fill, 'test-set'] = test_set\n",
    "    res.loc[index_to_fill, 'precision'] = round(precision_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'accuracy'] = round(accuracy_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'recall'] = round(recall_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'F1'] = round(f1_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'auc'] = round(auc, 2)\n",
    "    res.loc[index_to_fill, 'avg_prec'] = round(avg_prec, 2)\n",
    "    res.loc[index_to_fill, 'model'] = model_name\n",
    "    res.loc[index_to_fill, 'feat.'] = features_size\n",
    "    res.loc[index_to_fill, 'label-imb-train'] = round(label_imb_train, 2).item()\n",
    "    res.loc[index_to_fill, 'label-imb-test'] = round(label_imb_test, 2).item()\n",
    "    res.loc[index_to_fill, 'train-size'] = train_size\n",
    "    res.loc[index_to_fill, 'test-size'] = test_size\n",
    "    res.loc[index_to_fill, 'runtime(sec)'] = round(duration, 2)\n",
    "    return res\n",
    "\n",
    "#To test binning; not used in final results\n",
    "def calculate_metrics_multiclass(y_true, y_pred, duration, dataset, obs_col, model_name, model_run, smote,\n",
    "                             test_set, features_size, label_imb_train, label_imb_test, \n",
    "                             train_size, test_size):\n",
    "    res = pd.DataFrame(columns=['dataset', 'obs_col', 'model', 'model_run', 'smote',\n",
    "     'precision', 'recall', 'F1', 'accuracy', 'auc','avg_prec', 'feat.', 'label-imb-train', \n",
    "                                'label-imb-test', 'train-size', 'test-size', 'runtime(sec)'])\n",
    "    index_to_fill = res.shape[0]\n",
    "    #auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "    # AUPRC\n",
    "    #precision, recall, thresholds = metrics.precision_recall_curve(y_true, y_pred)\n",
    "    #avg_prec = metrics.auc(recall, precision)\n",
    "    res.loc[index_to_fill, 'dataset']= dataset\n",
    "    res.loc[index_to_fill, 'obs_col']=obs_col\n",
    "    res.loc[index_to_fill, 'model_run']=model_run\n",
    "    #res.loc[index_to_fill, 'exp_type'] = exp_type\n",
    "    res.loc[index_to_fill, 'smote'] = smote\n",
    "    res.loc[index_to_fill, 'test-set'] = test_set\n",
    "    res.loc[index_to_fill, 'precision'] = round(precision_score(y_true, y_pred, average='micro'), 2)\n",
    "    res.loc[index_to_fill, 'accuracy'] = round(accuracy_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'recall'] = round(recall_score(y_true, y_pred, average='micro'), 2)\n",
    "    res.loc[index_to_fill, 'F1'] = round(f1_score(y_true, y_pred, average='micro'), 2)\n",
    "    #res.loc[index_to_fill, 'auc'] = round(auc, 2)\n",
    "    #res.loc[index_to_fill, 'avg_prec'] = round(avg_prec, 2)\n",
    "    res.loc[index_to_fill, 'model'] = model_name\n",
    "    res.loc[index_to_fill, 'feat.'] = features_size\n",
    "    res.loc[index_to_fill, 'label-imb-train'] = ' '.join(str(x) for x in round(label_imb_train,2))\n",
    "    res.loc[index_to_fill, 'label-imb-test'] = ' '.join(str(x) for x in round(label_imb_test,2))\n",
    "    res.loc[index_to_fill, 'train-size'] = train_size\n",
    "    res.loc[index_to_fill, 'test-size'] = test_size\n",
    "    res.loc[index_to_fill, 'runtime(sec)'] = round(duration, 2)\n",
    "    return res\n",
    "\n",
    "def interpret_ml(x_train, x_test, x_header_names, model, output_directory, case):\n",
    "    import shap\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "    shap_values_idx = 1\n",
    "\n",
    "    # save shap values in tabular format\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.mkdir(output_directory)\n",
    "    shap_values_df = pd.DataFrame(data=shap_values[shap_values_idx], columns=[i + '_shp' for i in x_header_names])\n",
    "    shap_values_df.to_csv(os.path.join(output_directory, 'shap-values-RF-' + case + '.csv'), index=False)\n",
    "\n",
    "    plt.clf()\n",
    "    shap.summary_plot(shap_values[shap_values_idx], x_test, feature_names=x_header_names, show=False)\n",
    "    plt.yticks(fontname=\"Times New Roman\")\n",
    "    plt.xticks(fontname=\"Times New Roman\")\n",
    "    plt.tick_params(axis='both', which='major', labelsize=23)\n",
    "    plt.xlabel('SHAP value (impact on model output - pos. class)', fontname=\"Times New Roman\", fontsize=22)\n",
    "    plt.savefig(os.path.join(output_directory, 'shap-summary-plot-RF-' + case + '.eps'), bbox_inches='tight', format='eps') #For print quality figures\n",
    "    plt.savefig(os.path.join(output_directory, 'shap-summary-plot-RF-' + case + '.png'), bbox_inches='tight')\n",
    "    pd.DataFrame(x_test).to_csv(os.path.join(output_directory, case + '-test.csv')) #For mapping results\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8c9a4-6499-4f95-9c0d-1cba1c48cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def get_cols(data_coll, allVars):\n",
    "    resp_cols = []\n",
    "    for var in allVars:\n",
    "        varcols=[col for col in data_coll.columns if col.startswith(var)]\n",
    "        resp_cols.append(varcols)\n",
    "    resp_cols=list(chain(*resp_cols))\n",
    "    column_indices = [data_coll.columns.get_loc(col) for col in resp_cols]\n",
    "    return(resp_cols, column_indices)\n",
    "\n",
    "def get_best_vars(varlabels, resp_cols):\n",
    "    colnames=[]\n",
    "    for i in varlabels:\n",
    "        index=i.replace(\"x\",\"\")\n",
    "        colnames.append(resp_cols[int(index)])\n",
    "    return(colnames)\n",
    "\n",
    "def save_preds(data, y_true, y_pred, outpath):\n",
    "    data_out = data[[\"enum\", \"month\", \"obs_year\", \"lat\", \"lon\", \"rural\", \"cat\"]]\n",
    "    data_out.loc[:,\"obs\"]=y_true\n",
    "    data_out.loc[:,\"pred\"]=y_pred\n",
    "    data_out['pred_type']=np.where((data_out['obs']==0) & (data_out['pred']==0), 'tn', \n",
    "                                    np.where((data_out['obs']==1) & (data_out['pred']==0), 'fn',\n",
    "                                             np.where((data_out['obs']==0) & (data_out['pred']==1), 'fp', 'tp')))\n",
    "    data_out.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ed065-4fe8-458f-af8c-ec6979de4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the single dataset - this can be skipped\n",
    "hunger_lc=pd.read_csv(\"Datasets/hunger_lc.csv\", index_col=0)\n",
    "mzprice = pd.read_csv(\"Datasets/mzprice_final.csv\")\n",
    "sat_final = pd.read_csv(\"Datasets/sat_final.csv\", index_col=0)\n",
    "ea_regions = pd.read_csv(\"Datasets/ea_regions.csv\")\n",
    "ea_dists = pd.read_csv(\"ea_dists.csv\")\n",
    "lsms_vars = pd.read_csv(\"Datasets/ea_geovars_all.csv\")\n",
    "panel=pd.read_csv(\"Datasets/panel_eas.csv\")\n",
    "mzprice_infl = pd.read_csv(\"Datasets/mzprice_final_annualchg.csv\", index_col=0)\n",
    "regionnums = pd.DataFrame({\"region\" : [\"North\", \"Central\", \"South\"], \"regionnum\": [1,2,3]})\n",
    "hunger_lc=hunger_lc.drop_duplicates().reset_index(drop=True) #Forgot to do this step on export.\n",
    "\n",
    "print(len(sat_final))\n",
    "data_coll = sat_final.merge(lsms_vars, on=['ea_id', 'wave'])\n",
    "print(len(data_coll))\n",
    "data_coll = data_coll.merge(panel, on=['ea_id'], how='inner')\n",
    "print(len(data_coll))\n",
    "data_coll = data_coll.merge(hunger_lc, on=['ea_id','obs_year'])\n",
    "print(len(data_coll))\n",
    "data_coll = data_coll.merge(mzprice, on=['ea_id', 'obs_year','obs_monthnum'])\n",
    "print(len(data_coll))\n",
    "data_coll = data_coll.merge(ea_regions, on=\"ea_id\")\n",
    "print(len(data_coll))\n",
    "data_coll = data_coll.merge(regionnums, on=\"region\")\n",
    "print(len(data_coll))\n",
    "data_coll=data_coll.merge(mzprice_infl, on=['ea_id', 'obs_year','obs_monthnum'])\n",
    "print(len(data_coll))\n",
    "data_coll = data_coll.merge(ea_dists[[\"ea_id\",\"distnum\"]], on=\"ea_id\")\n",
    "data_coll=data_coll.rename(columns={\"ea_id\" : \"enum\"})\n",
    "data_coll=data_coll.loc[:,~data_coll.columns.str.startswith(('year_offset', 'obs_month_', 'nightlights'))] #Cruft; nightlights too messy to use directly.\n",
    "data_coll[\"cat_cat1\"]=np.where(data_coll[\"cat\"]>2, 1,0)\n",
    "data_coll[\"cat_cat2\"]=np.where(data_coll[\"cat\"]>3, 1,0)\n",
    "region_dummies = pd.get_dummies(data_coll['region'])\n",
    "data_coll=data_coll.drop(['region', 'regionnum', 'lsms_aez'], axis=1)\n",
    "data_coll=data_coll.join(region_dummies)\n",
    "data_coll['offset']=data_coll['obs_monthnum']-3\n",
    "data_coll['offset']=np.where(data_coll['offset']<0, data_coll['offset']+12, data_coll['offset'])\n",
    "data_coll=data_coll.rename(columns={\"South\": \"region_south\", \"North\": \"region_north\", \"Central\": \"region_central\"})\n",
    "data_coll['qtr1']=np.where((data_coll['obs_monthnum']==12) | (data_coll['obs_monthnum']==1) | (data_coll['obs_monthnum']==2),\n",
    "                          1, 0)\n",
    "data_coll['qtr2']=np.where((data_coll['obs_monthnum']==3) | (data_coll['obs_monthnum']==4) | (data_coll['obs_monthnum']==5),\n",
    "                          1,0)\n",
    "data_coll['qtr3']=np.where((data_coll['obs_monthnum']==6) | (data_coll['obs_monthnum']==7) | (data_coll['obs_monthnum']==8),\n",
    "                           1, 0)\n",
    "data_coll['mzprice_qtrchg']=(data_coll['mzprice_lag1']+data_coll['mzprice_lag2']+data_coll['mzprice_lag3'])/(data_coll['mzprice_lag4']+data_coll['mzprice_lag5']+data_coll['mzprice_lag6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4c778-bc55-4327-8661-677f75946905",
   "metadata": {},
   "outputs": [],
   "source": [
    "genl_infl = pd.read_csv(\"Datasets/monthly_inflation.csv\")\n",
    "for i in range(1,13):\n",
    "    genl_infl['obs_monthnum'] = genl_infl['obs_monthnum']+1\n",
    "    genl_infl['obs_year'] = np.where(genl_infl['obs_monthnum'] > 12, genl_infl['obs_year']+1, genl_infl['obs_year'])\n",
    "    genl_infl['obs_monthnum']=np.where(genl_infl['obs_monthnum']>12, genl_infl['obs_monthnum']-12, genl_infl['obs_monthnum'])\n",
    "    genl_infl_merge=genl_infl.copy()\n",
    "    genl_infl_merge[f'inflationcpi_lag{i}']=genl_infl_merge['inflation']\n",
    "    genl_infl_merge=genl_infl_merge.drop(columns=['inflation'])\n",
    "    data_coll = data_coll.merge(genl_infl_merge, on=['obs_year', 'obs_monthnum'])\n",
    "    \n",
    "mzmeans = pd.read_csv(\"Datasets/mznorms.csv\", index_col=0)\n",
    "mzmeans = mzmeans.rename(columns={\"obs_month\": \"obs_monthnum\"})\n",
    "for i in range(1,13):\n",
    "    mzmeans['obs_monthnum'] = mzmeans['obs_monthnum']+1\n",
    "    mzmeans['obs_year'] = np.where(mzmeans['obs_monthnum'] > 12, mzmeans['obs_year']+1, mzmeans['obs_year'])\n",
    "    mzmeans['obs_monthnum']=np.where(mzmeans['obs_monthnum']>12, mzmeans['obs_monthnum']-12, mzmeans['obs_monthnum'])\n",
    "    mzmeans_merge=mzmeans.copy()\n",
    "    mzmeans_merge[f'mz_mean_lag{i}']=mzmeans_merge['mz_mean']\n",
    "    mzmeans_merge[f'mz_sd_lag{i}']=mzmeans_merge['mz_sd']\n",
    "    mzmeans_merge=mzmeans_merge.drop(columns=['mz_mean', 'mz_sd'])\n",
    "    data_coll = data_coll.merge(mzmeans_merge, on=['obs_year', 'obs_monthnum'])\n",
    "    data_coll[f'mznorm_lag{i}']=(data_coll[f'mzprice_lag{i}']-data_coll[f'mz_mean_lag{i}'])/data_coll[f'mz_sd_lag{i}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023964d5-b4bd-4771-931e-ee73fdab14d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_coll.to_csv(\"data_coll_allvars.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498961f5-0130-4e66-8629-a9807e5d81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using normalized climatological variables instead; not in final paper.\n",
    "data_coll_norms = data_coll.copy()\n",
    "norms = pd.read_csv(\"Datasets/TerraClimateNorms.csv\")\n",
    "norms = norms.loc[:, ~norms.columns.str.startswith('pdsi')] #Already normalized.\n",
    "data_coll_norms = data_coll_norms.merge(norms, left_on='enum',  right_on=\"ea_id\")\n",
    "print(len(data_coll_norms))\n",
    "tc_vars = ['ppt','soil','vap','vpd']\n",
    "for var in tc_vars:\n",
    "    for month in months:\n",
    "        data_coll_norms[f'norm_{var}_{month}'] = (data_coll_norms[f'{var}_{month}']-data_coll_norms[f'{var}_mean_{month}'])/data_coll_norms[f'{var}_sd_{month}']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06405b0-9182-4269-97ea-5aaa2fb097ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Condensing some variables to the season level; not in final paper\n",
    "data_coll_season = data_coll.copy()\n",
    "data_coll_season = data_coll_season.loc[:, ~data_coll_season.columns.str.startswith(('ppt', 'ndvi', 'lc'))]\n",
    "data_coll_season = data_coll_season.loc[:, ~data_coll_season.columns.str.endswith(('may','jun','jul','aug','sep'))]\n",
    "data_coll_season['ppt_wet']=data_coll['ppt_oct']+data_coll['ppt_dec']+data_coll['ppt_jan']+data_coll['ppt_feb']+data_coll['ppt_mar']+data_coll['ppt_apr']\n",
    "data_coll_season['ppt_max']=data_coll[['ppt_oct', 'ppt_dec', 'ppt_jan', 'ppt_feb', 'ppt_mar', 'ppt_apr']].max(axis=1)\n",
    "gr_seas=['sep','oct','nov','dec','jan','feb','mar','apr']\n",
    "for mon in range(1,8):\n",
    "    data_coll_season[f'ndvi_chg_{gr_seas[mon]}']=data_coll[f'ndvi_{gr_seas[mon]}']-data_coll[f'ndvi_{gr_seas[(mon-1)]}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6cd22c-9043-4c4a-be8f-149c7da224aa",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f26cad-7927-468b-9cea-d9f0baeb2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_cols=[\"cat_cat1\", \"cat_cat2\"]\n",
    "#Leftover\n",
    "test_fraction=0.2\n",
    "model_names = ['logistic-regression', 'lasso', 'random-forest','tabnet']\n",
    "#model_names=['random-forest']\n",
    "naive_vars = ['region', 'qtr', 'rural']\n",
    "satVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "               'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "               'lcgrass','lccrop'] \n",
    "priceVars = ['mzprice']\n",
    "priceNorm = ['mznorm']\n",
    "surveys = [1,3,4]\n",
    "lsmsVars = ['lsms']\n",
    "inflVars = ['mzinfl', 'inflation']\n",
    "dataset='normal_allvars'\n",
    "\n",
    "model_runs = [\"naive\",\"remote\",\"price\",'lsms', 'infl', 'infl+lsms',\n",
    "              'infl+remote', \"price+infl\", \"price+remote\",\"price+lsms\", \n",
    "              \"sat+lsms\", \"selected\", 'infl+remote-naive', \"all\"]\n",
    "\n",
    "for obs_col in obs_cols:\n",
    "    res = pd.DataFrame(columns=['dataset', 'obs_col', 'model', 'model_run',  'smote', 'test-set',\n",
    " 'precision', 'recall', 'F1', 'accuracy', 'auc','avg_prec', 'feat.', 'label-imb-train', \n",
    "                            'label-imb-test', 'train-size', 'test-size', 'runtime(sec)'])\n",
    "    outdir=f\"Experiment 1 - {obs_col[-4:]}\"\n",
    "    selected_features = pd.DataFrame(columns=[\"wave\", \"dataset_num\", \"obs_col\", \"selectedvars\"])\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(outdir, \"Confusion Matrices\")):\n",
    "        os.mkdir(os.path.join(outdir, \"Confusion Matrices\"))\n",
    "\n",
    "    if obs_col==\"cat_cat1\":\n",
    "        smoteout=False\n",
    "    else: \n",
    "        smoteout=True\n",
    "    for ds in tqdm(range(1,6)):\n",
    "        for survey in tqdm(surveys):\n",
    "            data_coll_wave=pd.read_csv(f\"Subsamples/data_coll_samp{ds}_wave{survey}_train.csv\")\n",
    "            #Unused columns\n",
    "            data_coll_wave.drop(columns=['mzprice_yoy', 'mzprice_qtrchg', 'region_central'], inplace=True)\n",
    "            data_coll=pd.read_csv(f'Subsamples/data_coll_samp{ds}_wave{survey}_test.csv')\n",
    "            data_coll.drop(columns=['mzprice_yoy', 'mzprice_qtrchg','region_central'],inplace=True)\n",
    "    \n",
    "            clf = Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('feature_selection', SelectFromModel(ExtraTreesClassifier(n_estimators=1000, random_state=0)))\n",
    "            ])\n",
    "            allVars=naive_vars + satVars + priceVars+lsmsVars+inflVars\n",
    "            resp_cols, column_indices = get_cols(data_coll, allVars)\n",
    "            X_train = data_coll_wave.loc[:, resp_cols]\n",
    "            y_train = data_coll_wave.loc[:, obs_col] \n",
    "    \n",
    "            clf.fit(X_train, y_train.values.ravel())\n",
    "            selecVars=clf[:-1].get_feature_names_out()\n",
    "            for model_name in tqdm(model_names):\n",
    "                model=None\n",
    "                if model_name == 'logistic-regression':\n",
    "                    model = LogisticRegression(penalty=None)\n",
    "                if model_name == 'lasso':\n",
    "                    model= LogisticRegression(penalty='l1', solver='liblinear')\n",
    "                if model_name == 'random-forest':\n",
    "                    model = RandomForestClassifier(random_state=42)\n",
    "                if model_name == 'tabnet':\n",
    "                    model = TabNetClassifier(verbose=0,seed=42)\n",
    "    \n",
    "                for model_run in tqdm(model_runs):\n",
    "                    if model_run=='naive':\n",
    "                        allVars=naive_vars\n",
    "                    elif model_run==\"remote\":\n",
    "                        allVars= satVars+naive_vars\n",
    "                    elif model_run==\"price\":\n",
    "                        allVars= priceVars+naive_vars\n",
    "                    elif model_run==\"price+infl\":\n",
    "                        allVars=priceVars+inflVars+naive_vars\n",
    "                    elif model_run==\"price+lsms\":\n",
    "                        allVars=priceVars+lsmsVars+naive_vars\n",
    "                    elif model_run==\"lsms\": \n",
    "                        allVars=lsmsVars+naive_vars\n",
    "                    elif model_run==\"sat+lsms\":\n",
    "                        allVars=satVars+lsmsVars+naive_vars\n",
    "                    elif model_run==\"infl+lsms\":\n",
    "                        allVars=inflVars+lsmsVars\n",
    "                    elif model_run==\"infl+remote\":\n",
    "                        allVars=inflVars+naive_vars+satVars\n",
    "                    elif model_run==\"infl+remote-naive\":\n",
    "                        allVars=inflVars+satVars\n",
    "                    elif model_run==\"selected\":\n",
    "                        allVars=selecVars\n",
    "                    elif model_run==\"infl\":\n",
    "                        allVars=inflVars\n",
    "                    elif model_run==\"all\":\n",
    "                        allVars=naive_vars + satVars + priceVars + lsmsVars+inflVars\n",
    "                        \n",
    "                    if(model_run==\"selected\"):\n",
    "                        resp_cols=allVars\n",
    "                    else:\n",
    "                        resp_cols, _ = get_cols(X_train, allVars)\n",
    "    \n",
    "                    X_train_g=X_train.loc[:, resp_cols]\n",
    "                    y_train_g=y_train\n",
    "                    if (smoteout==True) & (model_run!=\"naive\"):\n",
    "                        cat_vars = []\n",
    "                        if 'region' in allVars:\n",
    "                            cat_vars = cat_vars + ['region_south','region_north']\n",
    "                        if 'rural' in allVars: \n",
    "                            cat_vars = cat_vars + ['rural']\n",
    "                        if 'qtr' in allVars:\n",
    "                            cat_vars = cat_vars + ['qtr1','qtr2','qtr3']\n",
    "                        if len(cat_vars) > 0:     \n",
    "                            smote=SMOTENC(categorical_features=cat_vars, random_state=42)\n",
    "                        else:\n",
    "                            smote=SMOTE(random_state=42)\n",
    "                        X_train_g, y_train_g=smote.fit_resample(X_train_g, y_train_g)\n",
    "                        smote=True\n",
    "                    else:\n",
    "                        smote=False\n",
    "    \n",
    "                    ts_df=data_coll.loc[:, :].reset_index(drop=True)\n",
    "    \n",
    "                    #resp_cols, _ = get_cols(data_coll, allVars)\n",
    "                    X_test_g=ts_df.loc[:, resp_cols]\n",
    "                    y_test_g=ts_df.loc[:, obs_col]\n",
    "    \n",
    "                    scaler = StandardScaler()\n",
    "                    X_train_g = scaler.fit_transform(X_train_g)\n",
    "                    X_test_g = scaler.transform(X_test_g)\n",
    "                    start_time = time.time()\n",
    "                    model.fit(X_train_g, y_train_g.values.ravel())\n",
    "                    duration = time.time() - start_time\n",
    "                    y_pred = model.predict(X_test_g)\n",
    "    \n",
    "                    # create confusion matrix\n",
    "                    cm = confusion_matrix(y_test_g, y_pred)\n",
    "                    cm=pd.DataFrame(cm)\n",
    "                    cm=cm.rename(index={0:\"True0\", 1:\"True1\"}, columns={0: \"Pred0\", 1:\"Pred1\"})\n",
    "    \n",
    "    \n",
    "                    test_set=f'{survey}'\n",
    "    \n",
    "    \n",
    "                    features_size = X_train_g.shape[1]\n",
    "                    label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "                    label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "                    #using imbalance ratio per label for non-binary data\n",
    "                    train_size = X_train_g.shape[0]\n",
    "                    test_size = X_test_g.shape[0]\n",
    "                    res= pd.concat([res, calculate_metrics_single(y_test_g, y_pred, duration, dataset, obs_col, model_name, model_run, \n",
    "                                                        smote, test_set, features_size, label_imb_train, label_imb_test, \n",
    "                                                        train_size, test_size)], axis=0)\n",
    "    \n",
    "    \n",
    "                    if not os.path.exists(os.path.join(outdir, \"Preds\")):\n",
    "                        os.mkdir(os.path.join(outdir, \"Preds\"))\n",
    "                    if not os.path.exists(os.path.join(outdir, f\"Preds/{model_name}\")):\n",
    "                        os.mkdir(os.path.join(outdir, f\"Preds/{model_name}\"))\n",
    "                    save_preds(ts_df, y_test_g, y_pred, os.path.join(outdir, f\"Preds/{model_name}\", f'preds_{obs_col}_{model_run}_r{ds}_wave{survey}.csv'))\n",
    "    \n",
    "                    if not os.path.exists(os.path.join(outdir, \"Confusion Matrices\")):\n",
    "                        os.mkdir(os.path.join(outdir, \"Confusion Matrices\"))\n",
    "                    if not os.path.exists(os.path.join(outdir, f\"Confusion Matrices/{model_name}\")):\n",
    "                        os.mkdir(os.path.join(outdir, f\"Confusion Matrices/{model_name}\"))\n",
    "                    cm.to_csv(os.path.join(outdir, f'Confusion Matrices/{model_name}/{obs_col}_{model_run}_r{ds}_wave{survey}.csv'))\n",
    "                    if(model_run==\"selected\"):\n",
    "                        index=len(selected_features)\n",
    "                        selected_features.loc[index, \"wave\"]=survey\n",
    "                        selected_features.loc[index, \"dataset_num\"]=ds\n",
    "                        selected_features.loc[index,\"selected_features\"]=\" \".join(allVars)\n",
    "                        selected_features.loc[index, \"obs_col\"]=obs_col\n",
    "                    #shap_output_dir=os.path.join(outdir, f'SHAP_{obs_col}_{model_name}_{model_run}_w{wave}')\n",
    "                    #modelout = model.steps[-1][1]\n",
    "                    #interpret_ml(X_train_g, X_test_g, resp_cols, modelout, shap_output_dir, model_run)\n",
    "                \n",
    "    res.to_csv(os.path.join(outdir, f'Exp1 Results {obs_col[-4:]}.csv'))\n",
    "    selected_features.to_csv(os.path.join(outdir, f'Exp1 Selected Features {obs_col[-4:]}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6a0422-e8b9-45c3-98d1-1123091ec30f",
   "metadata": {},
   "source": [
    "## SHAP Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b607ba3-dcc9-43b1-997a-b09c8e4bcb93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obs_cols=[\"cat_cat1\", \"cat_cat2\"]\n",
    "#model_names = ['logistic-regression', 'ridge', 'random-forest','tabnet']\n",
    "model_names=['random-forest']\n",
    "naive_vars = ['region', 'qtr', 'rural']\n",
    "satVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "               'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "               'lcgrass','lccrop'] \n",
    "priceVars = ['mzprice']\n",
    "priceNorm = ['mznorm']\n",
    "surveys = [1,3,4]\n",
    "lsmsVars = ['lsms']\n",
    "inflVars = ['mzinfl', 'inflation']\n",
    "dataset='normal_allvars'\n",
    "#model_runs = [\"naive\",\"remote\",\"price\",'lsms', 'infl', 'pricenorm',\n",
    "#              'pricenorm+infl', 'pricenorm+remote', 'pricenorm+lsms',\n",
    "#              \"price+infl\", \"price+remote\",\"price+lsms\", \n",
    "#              \"sat+lsms\", \"selected\", \"all\"]\n",
    "model_runs=['all']\n",
    "\n",
    "for obs_col in obs_cols:\n",
    "    outdir=f\"Experiment 1 - SHAP\"\n",
    "    res = pd.DataFrame(columns=['dataset', 'obs_col', 'model', 'model_run',  'smote', 'test-set',\n",
    "     'precision', 'recall', 'F1', 'accuracy', 'auc','avg_prec', 'feat.', 'label-imb-train', \n",
    "                                'label-imb-test', 'train-size', 'test-size', 'runtime(sec)'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    selected_features = pd.DataFrame(columns=[\"wave\", \"dataset_num\", \"obs_col\", \"selectedvars\"])\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    if obs_col==\"cat_cat1\":\n",
    "        smoteout=False\n",
    "    else: \n",
    "        smoteout=True\n",
    "    for survey in surveys:\n",
    "        for ds in range(3,4): #Just take the third dataset to reduce processing time - first one did not produce good fits as discussed in paper; 2-5 can be added to view similarity across samples\n",
    "            data_coll_wave=pd.read_csv(f\"Subsamples/data_coll_samp{ds}_wave{survey}_train.csv\")\n",
    "                #Unused columns\n",
    "            data_coll_wave.drop(columns=['mzprice_yoy', 'mzprice_qtrchg', 'region_central'], inplace=True)\n",
    "            data_coll_test=pd.read_csv(f'Subsamples/data_coll_samp{ds}_wave{survey}_test.csv')\n",
    "            data_coll_test.drop(columns=['mzprice_yoy', 'mzprice_qtrchg','region_central'],inplace=True)\n",
    "            \n",
    "            for model_name in model_names:\n",
    "                model = None\n",
    "                if model_name == 'logistic-regression':\n",
    "                    model = LogisticRegression(penalty='none')\n",
    "                if model_name == 'lasso':\n",
    "                    model= LogisticRegression(penalty='l1', solver='liblinear')\n",
    "                if model_name == 'random-forest':\n",
    "                    model = RandomForestClassifier()\n",
    "                if model_name == 'tabnet':\n",
    "                    model = TabNetClassifier(verbose=0,seed=42)\n",
    "    \n",
    "                for obs_col in tqdm(obs_cols):\n",
    "                    for model_run in tqdm(model_runs):\n",
    "                        if model_run=='naive':\n",
    "                            allVars=naive_vars\n",
    "                        elif model_run==\"remote\":\n",
    "                            allVars= satVars+naive_vars\n",
    "                        elif model_run==\"price\":\n",
    "                            allVars= priceVars+naive_vars\n",
    "                        elif model_run==\"price+infl\":\n",
    "                            allVars=priceVars+inflVars+naive_vars\n",
    "                        elif model_run==\"price+lsms\":\n",
    "                            allVars=priceVars+lsmsVars+naive_vars\n",
    "                        elif model_run==\"lsms\": \n",
    "                            allVars=lsmsVars+naive_vars\n",
    "                        elif model_run==\"sat+lsms\":\n",
    "                            allVars=satVars+lsmsVars+naive_vars\n",
    "                        elif model_run==\"infl+lsms\":\n",
    "                            allVars=inflVars+lsmsVars\n",
    "                        elif model_run==\"infl+remote\":\n",
    "                            allVars=inflVars+naive_vars+satVars\n",
    "                        elif model_run==\"infl+remote-naive\":\n",
    "                            allVars=inflVars+satVars\n",
    "                        elif model_run==\"selected\":\n",
    "                            allVars=selecVars\n",
    "                        elif model_run==\"infl\":\n",
    "                            allVars=inflVars+naive_vars\n",
    "                        elif model_run==\"all\":\n",
    "                            allVars=naive_vars + satVars + priceVars + lsmsVars+inflVars\n",
    "    \n",
    "                        if model_run!=\"selected\":\n",
    "                            resp_cols, _ = get_cols(data_coll_wave, allVars)\n",
    "                        else:\n",
    "                            resp_colls=\"allVars\"\n",
    "    \n",
    "                        X_train_g=data_coll_wave.loc[:, resp_cols]\n",
    "                        y_train_g=data_coll_wave.loc[:, obs_col]\n",
    "                        ts_df=data_coll_test\n",
    "                        #ts_df=data_coll_test.loc[data_coll['wave']==survey, :].reset_index(drop=True)\n",
    "                        X_test_g=ts_df.loc[:, resp_cols]\n",
    "                 \n",
    "                        \n",
    "                        if (smoteout==True) & (model_run!=\"naive\"):\n",
    "                            cat_vars = []\n",
    "                            if 'region' in allVars:\n",
    "                                cat_vars = cat_vars + ['region_south','region_north']\n",
    "                            if 'rural' in allVars:\n",
    "                                cat_vars = cat_vars + ['rural']\n",
    "                            if 'qtr' in allVars:\n",
    "                                cat_vars = cat_vars + ['qtr1','qtr2','qtr3']\n",
    "                            if len(cat_vars) > 0:     \n",
    "                                smote=SMOTENC(categorical_features=cat_vars, random_state=42)\n",
    "                            else:\n",
    "                                smote=SMOTE(random_state=42)\n",
    "                            X_train_g, y_train_g=smote.fit_resample(X_train_g, y_train_g)\n",
    "                            smote=True\n",
    "                        else:\n",
    "                            smote=False\n",
    "                        \n",
    "                        \n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_g = scaler.fit_transform(X_train_g)\n",
    "                        X_test_g = scaler.transform(X_test_g)\n",
    "                        start_time = time.time()\n",
    "                        model.fit(X_train_g, y_train_g.values.ravel())\n",
    "                        duration = time.time() - start_time\n",
    "                        #y_pred = model.predict(X_test_g)\n",
    "                        res= pd.concat([res, calculate_metrics_single(y_test_g, y_pred, duration, dataset, obs_col, model_name, model_run, \n",
    "                                                        smote, test_set, features_size, label_imb_train, label_imb_test, \n",
    "                                                        train_size, test_size)], axis=0)\n",
    "                        shap_output_dir=os.path.join(outdir, f'SHAP_{obs_col}_{model_name}_{model_run}_w{survey}')\n",
    "                        #modelout = model.steps[-1][1]\n",
    "                        interpret_ml(X_train_g, X_test_g, resp_cols, model, shap_output_dir, model_run)\n",
    "            \n",
    "    res.to_csv(os.path.join(outdir, f'Exp1 Results {obs_col}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da964751-532e-44f2-941e-9594dad851e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_coll_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d250f-57bb-4822-a695-a69adf6ae6c0",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d1659-fd62-4b15-8d1c-2193b4964e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_cols=[\"cat_cat1\", \"cat_cat2\"]\n",
    "model_names = ['logistic-regression', 'lasso', 'random-forest','tabnet']\n",
    "naive_vars = ['region', 'qtr', 'rural']\n",
    "satVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "               'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "               'lcgrass','lccrop'] \n",
    "priceVars = ['mzprice']\n",
    "priceNorm = ['mznorm']\n",
    "surveys = [2,3,4]\n",
    "lsmsVars = ['lsms']\n",
    "inflVars = ['mzinfl', 'inflation']\n",
    "dataset='normal_allvars'\n",
    "#smotes = [True, False]\n",
    "smoteout=True #Can be modified to compare smote/smoteless sampling.       \n",
    "#if not already loaded in\n",
    "#data_coll=pd.read_csv(\"data_coll_allvars.csv\")\n",
    "#data_coll=data_coll.drop(columns=['mzprice_yoy', 'region_central', 'mzprice_qtrchg'])\n",
    "\n",
    "model_runs = [\"naive\",\"remote\",\"price\",'lsms', 'infl', 'infl+lsms',\n",
    "              'infl+remote', \"price+infl\", \"price+remote\",\"price+lsms\", \n",
    "              \"sat+lsms\", \"selected\", 'infl+remote-naive', \"all\"]\n",
    "\n",
    "for obs_col in obs_cols:\n",
    "    outdir=f\"Experiment 2 - {obs_col}\"\n",
    "    res = pd.DataFrame(columns=['dataset', 'obs_col', 'model', 'model_run',  'smote', 'test-set',\n",
    " 'precision', 'recall', 'F1', 'accuracy', 'auc','avg_prec', 'feat.', 'label-imb-train', \n",
    "                            'label-imb-test', 'train-size', 'test-size', 'runtime(sec)'])\n",
    "    selected_features = pd.DataFrame(columns=[\"wave\", \"dataset_num\", \"obs_col\", \"selectedvars\"])\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    \n",
    "    if not os.path.exists(os.path.join(outdir, \"Confusion Matrices\")):\n",
    "        os.mkdir(os.path.join(outdir, \"Confusion Matrices\"))\n",
    "\n",
    "    if obs_col==\"cat_cat1\":\n",
    "        smoteout=False\n",
    "    else: \n",
    "        smoteout=True\n",
    "    \n",
    "    for ds in range(1,6):\n",
    "        data_coll_wave=pd.read_csv(f\"Subsamples/data_coll_samp{ds}_train_cat1.csv\") #This has both cat1 and cat2\n",
    "        data_coll_wave=data_coll_wave.drop(columns=['mzprice_yoy', 'region_central', 'mzprice_qtrchg'])\n",
    "        for survey in surveys:\n",
    "            clf = Pipeline([\n",
    "                ('scale', StandardScaler()),\n",
    "                ('feature_selection', SelectFromModel(ExtraTreesClassifier(n_estimators=1000, random_state=0)))\n",
    "            ])\n",
    "            allVars=naive_vars + satVars + priceVars+lsmsVars+inflVars\n",
    "            resp_cols, column_indices = get_cols(data_coll, allVars)\n",
    "            X_train = data_coll_wave.loc[data_coll_wave['wave']<survey, resp_cols]\n",
    "            y_train = data_coll_wave.loc[data_coll_wave['wave']<survey, obs_col] \n",
    "    \n",
    "            clf.fit(X_train, y_train.values.ravel())\n",
    "            selecVars=clf[:-1].get_feature_names_out()\n",
    "            \n",
    "            for model_name in model_names:\n",
    "                model = None\n",
    "                if model_name == 'logistic-regression':\n",
    "                    model = LogisticRegression(penalty=None)\n",
    "                if model_name == 'lasso':\n",
    "                    model= LogisticRegression(penalty='l1', solver='liblinear')\n",
    "                if model_name == 'random-forest':\n",
    "                    model = RandomForestClassifier()\n",
    "                if model_name == 'tabnet':\n",
    "                    model = TabNetClassifier(verbose=0,seed=42)\n",
    "    \n",
    "                for obs_col in tqdm(obs_cols):\n",
    "                    for model_run in tqdm(model_runs):\n",
    "                        if model_run=='naive':\n",
    "                            allVars=naive_vars\n",
    "                        elif model_run==\"remote\":\n",
    "                            allVars= satVars+naive_vars\n",
    "                        elif model_run==\"price\":\n",
    "                            allVars= priceVars+naive_vars\n",
    "                        elif model_run==\"price+infl\":\n",
    "                            allVars=priceVars+inflVars+naive_vars\n",
    "                        elif model_run==\"price+lsms\":\n",
    "                            allVars=priceVars+lsmsVars+naive_vars\n",
    "                        elif model_run==\"lsms\": \n",
    "                            allVars=lsmsVars+naive_vars\n",
    "                        elif model_run==\"sat+lsms\":\n",
    "                            allVars=satVars+lsmsVars+naive_vars\n",
    "                        elif model_run==\"infl+lsms\":\n",
    "                            allVars=inflVars+lsmsVars\n",
    "                        elif model_run==\"infl+remote\":\n",
    "                            allVars=inflVars+naive_vars+satVars\n",
    "                        elif model_run==\"infl+remote-naive\":\n",
    "                            allVars=inflVars+satVars\n",
    "                        elif model_run==\"selected\":\n",
    "                            allVars=selecVars\n",
    "                        elif model_run==\"infl\":\n",
    "                            allVars=inflVars+naive_vars\n",
    "                        elif model_run==\"all\":\n",
    "                            allVars=naive_vars + satVars + priceVars + lsmsVars+inflVars\n",
    "    \n",
    "                        if model_run!=\"selected\":\n",
    "                            resp_cols, _ = get_cols(X_train, allVars)\n",
    "                        else:\n",
    "                            resp_colls=\"allVars\"\n",
    "    \n",
    "                        X_train_g=X_train.loc[:, resp_cols]\n",
    "                        y_train_g=y_train\n",
    "                        \n",
    "                        ts_df=data_coll.loc[data_coll['wave']==survey, :].reset_index(drop=True)\n",
    "                        #resp_cols, _ = get_cols(data_coll, allVars)\n",
    "                        X_test_g=ts_df.loc[:, resp_cols]\n",
    "                        y_test_g=ts_df.loc[:, obs_col]\n",
    "\n",
    "                        \n",
    "                        if (smoteout==True) & (model_run!=\"naive\"):\n",
    "                            cat_vars = []\n",
    "                            if 'region' in allVars:\n",
    "                                cat_vars = cat_vars + ['region_south','region_north']\n",
    "                            if 'rural' in allVars:\n",
    "                                cat_vars = cat_vars + ['rural']\n",
    "                            if 'qtr' in allVars:\n",
    "                                cat_vars = cat_vars + ['qtr1','qtr2','qtr3']\n",
    "                            if len(cat_vars) > 0:     \n",
    "                                smote=SMOTENC(categorical_features=cat_vars, random_state=42)\n",
    "                            else:\n",
    "                                smote=SMOTE(random_state=42)\n",
    "                            X_train_g, y_train_g=smote.fit_resample(X_train_g, y_train_g)\n",
    "                            smote=True\n",
    "                        else:\n",
    "                            smote=False\n",
    "                        \n",
    "                        \n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_g = scaler.fit_transform(X_train_g)\n",
    "                        X_test_g = scaler.transform(X_test_g)\n",
    "                        start_time = time.time()\n",
    "                        model.fit(X_train_g, y_train_g.values.ravel())\n",
    "                        duration = time.time() - start_time\n",
    "                        y_pred = model.predict(X_test_g)\n",
    "    \n",
    "                        # create confusion matrix\n",
    "                        cm = confusion_matrix(y_test_g, y_pred)\n",
    "                        cm=pd.DataFrame(cm)\n",
    "                        cm.rename(index={0:\"True0\", 1:\"True1\"}, columns={0: \"Pred0\", 1:\"Pred1\"})\n",
    "    \n",
    "                        test_set=f'round{ds}_survey{survey}'\n",
    "    \n",
    "    \n",
    "                        features_size = X_train_g.shape[1]\n",
    "                        label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "                        label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "                        #using imbalance ratio per label for non-binary data\n",
    "    \n",
    "    \n",
    "                        train_size = X_train_g.shape[0]\n",
    "                        test_size = X_test_g.shape[0]\n",
    "    \n",
    "                        res= pd.concat([res, calculate_metrics_single(y_test_g, y_pred, duration, dataset, obs_col, model_name, model_run, \n",
    "                                                            smote, test_set, features_size, label_imb_train, label_imb_test, \n",
    "                                                            train_size, test_size)], axis=0)\n",
    "    \n",
    "    \n",
    "                        if not os.path.exists(os.path.join(outdir, \"Preds\")):\n",
    "                            os.mkdir(os.path.join(outdir, \"Preds\"))\n",
    "                        if not os.path.exists(os.path.join(outdir, f\"Preds/{model_name}\")):\n",
    "                            os.mkdir(os.path.join(outdir, f\"Preds/{model_name}\"))\n",
    "                        save_preds(ts_df, y_test_g, y_pred, os.path.join(outdir, f\"Preds/{model_name}\", f'preds_{obs_col}_{model_run}_r{ds}_wave{survey}.csv'))\n",
    "    \n",
    "                        if not os.path.exists(os.path.join(outdir, \"Confusion Matrices\")):\n",
    "                            os.mkdir(os.path.join(outdir, \"Confusion Matrices\"))\n",
    "                        if not os.path.exists(os.path.join(outdir, f\"Confusion Matrices/{model_name}\")):\n",
    "                            os.mkdir(os.path.join(outdir, f\"Confusion Matrices/{model_name}\"))\n",
    "                        cm.to_csv(os.path.join(outdir, f'Confusion Matrices/{model_name}/{obs_col}_{model_run}_r{ds}_wave{survey}.csv'))\n",
    "                        if(model_run==\"selected\"):\n",
    "                            index=len(selected_features)\n",
    "                            selected_features.loc[index, \"wave\"]=survey\n",
    "                            selected_features.loc[index, \"dataset_num\"]=ds\n",
    "                            selected_features.loc[index,\"selected_features\"]=\" \".join(allVars)\n",
    "                            selected_features.loc[index, \"obs_col\"]=obs_col\n",
    "                        #shap_output_dir=os.path.join(outdir, f'SHAP_{obs_col}_{model_name}_{model_run}_w{survey}')\n",
    "                        #modelout = model.steps[-1][1]\n",
    "                        #To do SHAP without a separate code block:\n",
    "                        #interpret_ml(X_train_g, X_test_g, resp_cols, model, shap_output_dir, model_run)\n",
    "                \n",
    "    res.to_csv(os.path.join(outdir, f\"Exp2 {obs_col} Results.csv\"))\n",
    "    selected_features.to_csv(os.path.join(outdir, f\"Exp2 {obs_col} Selected Features.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfed729-7ad4-4f94-8d52-89d5bf899c5a",
   "metadata": {},
   "source": [
    "### SHAP Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc975d00-4098-448c-96ad-0e220f1912bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_cols=[\"cat_cat1\", \"cat_cat2\"]\n",
    "model_names=['random-forest']\n",
    "naive_vars = ['region', 'qtr', 'rural']\n",
    "satVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "               'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "               'lcgrass','lccrop'] \n",
    "priceVars = ['mzprice']\n",
    "priceNorm = ['mznorm']\n",
    "surveys = [2,3,4]\n",
    "\n",
    "lsmsVars = ['lsms']\n",
    "inflVars = ['mzinfl', 'inflation']\n",
    "\n",
    "dataset='normal_allvars'\n",
    "#smotes = [True, False]\n",
    "\n",
    "\n",
    "res = pd.DataFrame(columns=['dataset', 'obs_col', 'model', 'model_run',  'smote', 'test-set',\n",
    " 'precision', 'recall', 'F1', 'accuracy', 'auc','avg_prec', 'feat.', 'label-imb-train', \n",
    "                            'label-imb-test', 'train-size', 'test-size', 'runtime(sec)'])\n",
    "\n",
    "\n",
    "#model_runs = [\"naive\",\"remote\",\"price\",'lsms', 'infl', 'pricenorm',\n",
    "#              'pricenorm+infl', 'pricenorm+remote', 'pricenorm+lsms',\n",
    "#              \"price+infl\", \"price+remote\",\"price+lsms\", \n",
    "#              \"sat+lsms\", \"selected\", \"all\"]\n",
    "\n",
    "#if not already loaded in\n",
    "data_coll=pd.read_csv(\"data_coll_allvars.csv\")\n",
    "data_coll = data_coll.drop(columns=['mzprice_yoy', 'region_central', 'mzprice_qtrchg'])\n",
    "\n",
    "model_runs=['all']\n",
    "outdir=\"Experiment 2 - SHAP\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "for obs_col in obs_cols:  \n",
    "    selected_features = pd.DataFrame(columns=[\"wave\", \"dataset_num\", \"obs_col\", \"selectedvars\"])\n",
    "    if obs_col==\"cat_cat1\":\n",
    "        smoteout=False\n",
    "    else:\n",
    "        smoteout=True\n",
    "    for survey in surveys:\n",
    "        for ds in range(3,4): #Just take the third dataset, as above; minor differences observed across all 5\n",
    "            data_coll_wave=pd.read_csv(f\"Subsamples/data_coll_samp{ds}_train_cat1.csv\") #This has both cat1 and cat2\n",
    "            data_coll_wave=data_coll_wave.drop(columns=['mzprice_yoy', 'region_central', 'mzprice_qtrchg'])\n",
    "            data_coll_wave=data_coll_wave.loc[data_coll_wave['wave']<survey,:]\n",
    "            for model_name in model_names:\n",
    "                model = None\n",
    "                if model_name == 'logistic-regression':\n",
    "                    model = LogisticRegression(penalty='none')\n",
    "                if model_name == 'lasso':\n",
    "                    model= LogisticRegression(penalty='l1', solver='liblinear')\n",
    "                if model_name == 'random-forest':\n",
    "                    model = RandomForestClassifier()\n",
    "                if model_name == 'tabnet':\n",
    "                    model = TabNetClassifier(verbose=0,seed=42)\n",
    "    \n",
    "                for obs_col in tqdm(obs_cols):\n",
    "                    for model_run in tqdm(model_runs):\n",
    "                        if model_run=='naive':\n",
    "                            allVars=naive_vars\n",
    "                        elif model_run==\"remote\":\n",
    "                            allVars= satVars+naive_vars\n",
    "                        elif model_run==\"price\":\n",
    "                            allVars= priceVars+naive_vars\n",
    "                        elif model_run==\"price+infl\":\n",
    "                            allVars=priceVars+inflVars+naive_vars\n",
    "                        elif model_run==\"price+lsms\":\n",
    "                            allVars=priceVars+lsmsVars+naive_vars\n",
    "                        elif model_run==\"lsms\": \n",
    "                            allVars=lsmsVars+naive_vars\n",
    "                        elif model_run==\"sat+lsms\":\n",
    "                            allVars=satVars+lsmsVars+naive_vars\n",
    "                        elif model_run==\"infl+lsms\":\n",
    "                            allVars=inflVars+lsmsVars\n",
    "                        elif model_run==\"infl+remote\":\n",
    "                            allVars=inflVars+naive_vars+satVars\n",
    "                        elif model_run==\"infl+remote-naive\":\n",
    "                            allVars=inflVars+satVars\n",
    "                        elif model_run==\"selected\":\n",
    "                            allVars=selecVars\n",
    "                        elif model_run==\"infl\":\n",
    "                            allVars=inflVars+naive_vars\n",
    "                        elif model_run==\"all\":\n",
    "                            allVars=naive_vars + satVars + priceVars + lsmsVars+inflVars\n",
    "    \n",
    "                        if model_run!=\"selected\":\n",
    "                            resp_cols, _ = get_cols(data_coll_wave, allVars)\n",
    "                        else:\n",
    "                            resp_colls=\"allVars\"\n",
    "    \n",
    "                        X_train_g=data_coll_wave.loc[:, resp_cols]\n",
    "                        y_train_g=data_coll_wave.loc[:, obs_col]\n",
    "                        \n",
    "                        ts_df=data_coll.loc[data_coll['wave']==survey, :].reset_index(drop=True)\n",
    "                        #resp_cols, _ = get_cols(data_coll, allVars)\n",
    "                        X_test_g=ts_df.loc[:, resp_cols]\n",
    "                        #y_test_g=ts_df.loc[:, obs_col]\n",
    "                        \n",
    "                        \n",
    "                        if (smoteout==True) & (model_run!=\"naive\"):\n",
    "                            cat_vars = []\n",
    "                            if 'region' in allVars:\n",
    "                                cat_vars = cat_vars + ['region_south','region_north']\n",
    "                            if 'rural' in allVars:\n",
    "                                cat_vars = cat_vars + ['rural']\n",
    "                            if 'qtr' in allVars:\n",
    "                                cat_vars = cat_vars + ['qtr1','qtr2','qtr3']\n",
    "                            if len(cat_vars) > 0:     \n",
    "                                smote=SMOTENC(categorical_features=cat_vars, random_state=42)\n",
    "                            else:\n",
    "                                smote=SMOTE(random_state=42)\n",
    "                            X_train_g, y_train_g=smote.fit_resample(X_train_g, y_train_g)\n",
    "                            smote=True\n",
    "                        else:\n",
    "                            smote=False\n",
    "                        \n",
    "                        scaler = StandardScaler()\n",
    "                        X_train_g = scaler.fit_transform(X_train_g)\n",
    "                        X_test_g = scaler.transform(X_test_g)\n",
    "                        start_time = time.time()\n",
    "                        model.fit(X_train_g, y_train_g.values.ravel())\n",
    "                        duration = time.time() - start_time\n",
    "                        #y_pred = model.predict(X_test_g)\n",
    "                        res= pd.concat([res, calculate_metrics_single(y_test_g, y_pred, duration, dataset, obs_col, model_name, model_run, \n",
    "                                                            smote, test_set, features_size, label_imb_train, label_imb_test, \n",
    "                                                            train_size, test_size)], axis=0)\n",
    "                        shap_output_dir=os.path.join(outdir, f'SHAP_{obs_col}_{model_name}_{model_run}_w{survey}')\n",
    "                        #modelout = model.steps[-1][1]\n",
    "                        interpret_ml(X_train_g, X_test_g, resp_cols, model, shap_output_dir, model_run)\n",
    "    res.to_csv(os.path.join(outdir, f\"Exp2 Results {obs_col}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fbbde-4114-4e9b-a759-29c46b33fee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
