{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # default is ‘last_expr’\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"D:/MWI Data\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "#import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "labels = ['Cat_0', 'Cat_1', 'Cat_2'] #Only three categories.\n",
    "\n",
    "years = ['2009', '2010', '2011', '2012','2013', '2014','2015', '2016', '2017', '2018', '2019']\n",
    "months = ['jan', 'feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "           'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "           'lcgrass','lccrop', 'mzprice_yoy','mzprice', \n",
    "           'region', 'month']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import time\n",
    "shap_output_dir = 'analysis_output/SHAP'\n",
    "\n",
    "res = pd.DataFrame(columns=[\n",
    "    'exp-type', 'test-set', 'model', 'precision', 'recall', 'F1', 'accuracy', 'auc', 'avg_prec',\n",
    "    'feat.', 'label-imb-train', 'label-imb-test', 'train-size', 'test-size', 'runtime(sec)'])\n",
    "\n",
    "def calculate_metrics_single(res, y_true, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size):\n",
    "    index_to_fill = res.shape[0]\n",
    "    res.loc[index_to_fill, 'exp-type'] = exp_type\n",
    "    res.loc[index_to_fill, 'test-set'] = test_set\n",
    "    res.loc[index_to_fill, 'precision'] = round(precision_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'accuracy'] = round(accuracy_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'recall'] = round(recall_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'F1'] = round(f1_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'model'] = model_name\n",
    "    res.loc[index_to_fill, 'feat.'] = features_size\n",
    "    res.loc[index_to_fill, 'label-imb-train'] = round(label_imb_train, 2)\n",
    "    res.loc[index_to_fill, 'label-imb-test'] = round(label_imb_test, 2)\n",
    "    res.loc[index_to_fill, 'train-size'] = train_size\n",
    "    res.loc[index_to_fill, 'test-size'] = test_size\n",
    "    res.loc[index_to_fill, 'runtime(sec)'] = round(duration, 2)\n",
    "    return res\n",
    "\n",
    "def calculate_metrics_multiclass(res, y_true, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size):\n",
    "    index_to_fill = res.shape[0]\n",
    "    # AUROC\n",
    "    #auc = metrics.roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
    "    # AUPRC\n",
    "    #precision, recall, thresholds = metrics.precision_recall_curve(y_true, y_pred, multi_class='ovr')\n",
    "    #avg_prec = metrics.auc(recall, precision)\n",
    "    res.loc[index_to_fill, 'exp-type'] = exp_type\n",
    "    res.loc[index_to_fill, 'test-set'] = test_set\n",
    "    res.loc[index_to_fill, 'precision'] = round(precision_score(y_true, y_pred, average='micro'), 2)\n",
    "    res.loc[index_to_fill, 'accuracy'] = round(accuracy_score(y_true, y_pred), 2)\n",
    "    res.loc[index_to_fill, 'recall'] = round(recall_score(y_true, y_pred, average='micro'), 2)\n",
    "    res.loc[index_to_fill, 'F1'] = round(f1_score(y_true, y_pred, average='micro'), 2)\n",
    "    #res.loc[index_to_fill, 'auc'] = round(auc, 2)\n",
    "    #res.loc[index_to_fill, 'avg_prec'] = round(avg_prec, 2)\n",
    "    res.loc[index_to_fill, 'model'] = model_name\n",
    "    res.loc[index_to_fill, 'feat.'] = features_size\n",
    "    res.loc[index_to_fill, 'label-imb-train'] = [round(x,2) for x in label_imb_train]\n",
    "    res.loc[index_to_fill, 'label-imb-test'] = [round(x, 2) for x in label_imb_test]\n",
    "    res.loc[index_to_fill, 'train-size'] = train_size\n",
    "    res.loc[index_to_fill, 'test-size'] = test_size\n",
    "    res.loc[index_to_fill, 'runtime(sec)'] = round(duration, 2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ac2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_ml(x_train, x_test, x_header_names, model, output_directory, case):\n",
    "    import shap\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "    shap_values_idx = 1\n",
    "\n",
    "    # save shap values in tabular format\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.mkdir(output_directory)\n",
    "    shap_values_df = pd.DataFrame(data=shap_values[shap_values_idx], columns=[i + '_shp' for i in x_header_names])\n",
    "    shap_values_df.to_csv(os.path.join(output_directory, 'shap-values-RF-' + case + '.csv'), index=False)\n",
    "\n",
    "    plt.clf()\n",
    "    shap.summary_plot(shap_values[shap_values_idx], x_test, feature_names=x_header_names, show=False)\n",
    "    plt.yticks(fontname=\"Times New Roman\")\n",
    "    plt.xticks(fontname=\"Times New Roman\")\n",
    "    plt.tick_params(axis='both', which='major', labelsize=23)\n",
    "    plt.xlabel('SHAP value (impact on model output - pos. class)', fontname=\"Times New Roman\", fontsize=22)\n",
    "    plt.savefig(os.path.join(output_directory, 'shap-summary-plot-RF-' + case + '.png'), bbox_inches='tight')\n",
    "\n",
    "    # plt.clf()\n",
    "    # shap.summary_plot(shap_values[shap_values_idx-1], x_test, feature_names=x_header_names)\n",
    "    # plt.yticks(fontname=\"Times New Roman\")\n",
    "    # plt.xticks(fontname=\"Times New Roman\")\n",
    "    # plt.tick_params(axis='both', which='major', labelsize=23)\n",
    "    # plt.xlabel('SHAP value (impact on model output - neg class)', fontname=\"Times New Roman\", fontsize=22)\n",
    "    # plt.savefig(os.path.join(output_directory, 'feat-analysis-shap-summary-plot-RF--neg-class.png'), bbox_inches='tight')\n",
    "\n",
    "\n",
    "    # # find feature importance in a tabular format\n",
    "    # global_shap_order = np.argsort(np.abs(shap_values[shap_values_idx]).mean(0))\n",
    "    # headers_sorted_reversed = [x_header_names[i] for i in global_shap_order]\n",
    "    # headers_sorted = headers_sorted_reversed[::-1]\n",
    "    \n",
    "    # for i in range(1, min(7, len(x_header_names))):\n",
    "    #     plt.clf()\n",
    "    #     shap.dependence_plot(str(headers_sorted[i]), shap_values[shap_values_idx], x_test, feature_names=x_header_names)\n",
    "    #     # plt.savefig(os.path.join(output_directory, headers_sorted[i] + '-shap-dependence-plot-RF--pos-class.png'), bbox_inches='tight')\n",
    "    \n",
    "    for i in range(len(x_header_names)):\n",
    "        plt.clf()\n",
    "        shap.dependence_plot(i, shap_values[shap_values_idx], np.array(x_test), feature_names=x_header_names)\n",
    "        plt.savefig(os.path.join(output_directory, case + x_header_names[i] + '-shap-dependence-plot-RF--pos-class.png'), bbox_inches='tight')\n",
    "        \n",
    "    pd.DataFrame(x_test).to_csv(os.path.join(output_directory, case + '-test.csv'))\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b126fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_irpl(df): \n",
    "    label_counts = df.value_counts().sort_index()\n",
    "    imbalance_ratios=(max(label_counts))/label_counts\n",
    "    return imbalance_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16e7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "\n",
    "# model_name = 'logistic-regression'\n",
    "model_name = 'random-forest'\n",
    "# model_name = 'xgboost'\n",
    "# model_name = 'lightgbm'\n",
    "# model_name = 'tabnet'\n",
    "\n",
    "model = None\n",
    "\n",
    "if model_name == 'logistic-regression':\n",
    "    model = LogisticRegression()\n",
    "\n",
    "if model_name == 'random-forest':\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "# if model_name == 'lightgbm':\n",
    "#     model = lgb.LGBMClassifier()\n",
    "\n",
    "# if model_name == 'xgboost':\n",
    "#     model = xgb.XGBClassifier()\n",
    "\n",
    "if model_name == 'tabnet':\n",
    "    model = TabNetClassifier(verbose=0,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "\n",
    "rcsi = pd.read_csv(\"RCSI/rcsi.csv\")\n",
    "rcsi_lc=pd.read_csv(\"RCSI/rcsi_lc.csv\", index_col=0)\n",
    "rcsi_mzprice = pd.read_csv(\"RCSI/rcsi_mzprice_final.csv\", index_col=0)\n",
    "rcsi_sat = pd.read_csv(\"RCSI/rcsi_sat_final.csv\", index_col=0)\n",
    "ea_regions = pd.read_csv(\"ea_regions.csv\")\n",
    "\n",
    "regionnums = pd.DataFrame({\"region\" : [\"North\", \"Central\", \"South\"], \"regionnum\": [1,2,3]})\n",
    "\n",
    "rcsi_coll = rcsi_sat.merge(rcsi_lc, on=['ea_id','obs_year'])\n",
    "rcsi_coll = rcsi_coll.merge(rcsi_mzprice, on=['ea_id', 'obs_year','obs_monthnum'])\n",
    "rcsi_coll = rcsi_coll.merge(ea_regions, on=\"ea_id\")\n",
    "rcsi_coll = rcsi_coll.merge(regionnums, on=\"region\")\n",
    "rcsi_coll=rcsi_coll.rename(columns={\"obs_monthnum\": \"month\", \"ea_id\" : \"enum\"})\n",
    "rcsi_coll['month']=rcsi_coll['month']-4\n",
    "rcsi_coll['month']=np.where(rcsi_coll['month']<0, rcsi_coll['month']+12, rcsi_coll['month'])\n",
    "region_dummies = pd.get_dummies(rcsi_coll['region'])\n",
    "rcsi_coll=rcsi_coll.drop(['region', 'regionnum'], axis=1)\n",
    "rcsi_coll=rcsi_coll.join(region_dummies)\n",
    "rcsi_coll=rcsi_coll.rename(columns={\"South\": \"region_south\", \"North\": \"region_north\", \"Central\": \"region_central\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fde74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcsi_coll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa954f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear results matrix\n",
    "res = pd.DataFrame(columns=[\n",
    "    'exp-type', 'test-set', 'model', 'precision', 'recall', 'F1', 'accuracy', 'auc', 'avg_prec',\n",
    "    'feat.', 'label-imb-train', 'label-imb-test', 'train-size', 'test-size', 'runtime(sec)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(RandomForestClassifier().get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from itertools import chain\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# split data for geographical division\n",
    "\n",
    "model_runs = [\"naive\",\"full\"]\n",
    "obs_columns=[\"rcsi_EAlevel\", \"rcsi_HHlevel\"]\n",
    "test_fraction=0.2\n",
    "\n",
    "#for test_fraction in [0.2]: #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "for model_type in model_runs: \n",
    "    if model_type=='full':\n",
    "        allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "           'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "           'lcgrass','lccrop', 'mzprice', \n",
    "           'region', 'month_offset']\n",
    "    else:\n",
    "        allVars=['region', 'month']\n",
    "    resp_cols = []\n",
    "    for var in allVars:\n",
    "        varcols=[col for col in rcsi_coll.columns if col.startswith(var)]\n",
    "        resp_cols.append(varcols)\n",
    "    resp_cols=list(chain(*resp_cols))\n",
    "    column_indices = [rcsi_coll.columns.get_loc(col) for col in resp_cols]\n",
    "    for obs_col in obs_columns: \n",
    "        exp_type = f'{obs_col}-enum-split-nosmote-{model_type}'\n",
    "        test_set = 'random-enums-'+str(int(test_fraction*100))+'%'\n",
    "\n",
    "        unique_enums = list(rcsi_coll['enum'].unique())\n",
    "        test_set_enums = sample(unique_enums,round(test_fraction*len(unique_enums)))\n",
    "        train_set_enums = [x for x in unique_enums if x not in test_set_enums]\n",
    "\n",
    "\n",
    "        tr_df = rcsi_coll.merge(pd.DataFrame (train_set_enums, columns = ['selected_enums_train']), left_on='enum', right_on='selected_enums_train')\n",
    "        ts_df = rcsi_coll.merge(pd.DataFrame (test_set_enums, columns = ['selected_enums_test']), left_on='enum', right_on='selected_enums_test')\n",
    "        tr_df.drop(columns='selected_enums_train', inplace=True)\n",
    "        ts_df.drop(columns='selected_enums_test', inplace=True)\n",
    "\n",
    "        y_test_g = ts_df.loc[:, obs_col]\n",
    "        y_train_g = tr_df.loc[:, obs_col]\n",
    "\n",
    "        X_test_g = ts_df.loc[:, ts_df.columns[column_indices]]\n",
    "        X_train_g = tr_df.loc[:, tr_df.columns[column_indices]]\n",
    "\n",
    "        cols = ts_df.columns[column_indices]\n",
    "\n",
    "        # dataset stats\n",
    "\n",
    "        features_size = X_train_g.shape[1]\n",
    "        #irpl_train =  #Imbalance ratio per label\n",
    "        #label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "        #label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "        #using imbalance ratio per label for non-binary data\n",
    "        label_imb_train = class_irpl(y_train_g)\n",
    "        label_imb_test = class_irpl(y_test_g)\n",
    "        train_size = X_train_g.shape[0]\n",
    "        test_size = X_test_g.shape[0]\n",
    "\n",
    "        # feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_g = scaler.fit_transform(X_train_g)\n",
    "        X_test_g = scaler.transform(X_test_g)\n",
    "\n",
    "        # train model\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_g, y_train_g)\n",
    "        duration = time.time() - start_time\n",
    "        y_pred = model.predict(X_test_g)\n",
    "\n",
    "        # create confusion matrix\n",
    "        cm = confusion_matrix(y_test_g, y_pred)\n",
    "        cm\n",
    "\n",
    "        # compute all metrics\n",
    "        res = calculate_metrics_multiclass(res, y_test_g, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size)\n",
    "    \n",
    "res   \n",
    "    #shap_output_dir = 'analysis_output/SHAP_mult_{}'.format(obs_col)\n",
    "    #interpret_ml(X_train_g, X_test_g, cols, model, shap_output_dir, exp_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# split data for geographical division\n",
    "\n",
    "\n",
    "model_runs = [\"naive\",\"full\"]\n",
    "obs_columns=[\"rcsi_EAlevel\", \"rcsi_HHlevel\"]\n",
    "test_fraction=0.2\n",
    "\n",
    "#for test_fraction in [0.2]: #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "for model_type in model_runs: \n",
    "    if model_type=='full':\n",
    "        allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "           'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "           'lcgrass','lccrop', 'mzprice_yoy','mzprice', \n",
    "           'region', 'month']\n",
    "    else:\n",
    "        allVars=['region', 'month']\n",
    "    resp_cols = []\n",
    "    for var in allVars:\n",
    "        varcols=[col for col in rcsi_coll.columns if col.startswith(var)]\n",
    "        resp_cols.append(varcols)\n",
    "    resp_cols=list(chain(*resp_cols))\n",
    "    column_indices = [rcsi_coll.columns.get_loc(col) for col in resp_cols]\n",
    "    for obs_col in obs_columns: \n",
    "        exp_type = f'{obs_col}-enum-split-smote-{model_type}'\n",
    "        smote=SMOTE()\n",
    "        X_vars = rcsi_coll.loc[:, rcsi_coll.columns[column_indices]]\n",
    "        Y_vars = rcsi_coll[obs_col]\n",
    "        X_res, Y_res = smote.fit_resample(X_vars, Y_vars)\n",
    "\n",
    "        test_set = 'random-enums-'+str(int(test_fraction*100))+'%'\n",
    "\n",
    "        X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "        X_res, Y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "        cols = rcsi_coll.columns[column_indices]\n",
    "\n",
    "        # dataset stats\n",
    "\n",
    "        features_size = X_train_g.shape[1]\n",
    "        #irpl_train =  #Imbalance ratio per label\n",
    "        #label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "        #label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "        #using imbalance ratio per label for non-binary data\n",
    "        label_imb_train = class_irpl(y_train_g)\n",
    "        label_imb_test = class_irpl(y_test_g)\n",
    "        train_size = X_train_g.shape[0]\n",
    "        test_size = X_test_g.shape[0]\n",
    "\n",
    "        # feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_g = scaler.fit_transform(X_train_g)\n",
    "        X_test_g = scaler.transform(X_test_g)\n",
    "\n",
    "        # train model\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_g, y_train_g)\n",
    "        duration = time.time() - start_time\n",
    "        y_pred = model.predict(X_test_g)\n",
    "\n",
    "        # create confusion matrix\n",
    "        cm = confusion_matrix(y_test_g, y_pred)\n",
    "        cm\n",
    "\n",
    "        # compute all metrics\n",
    "        res = calculate_metrics_multiclass(res, y_test_g, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size)\n",
    "        #shap_output_dir = 'analysis_output/SHAP_mult_{}_smote'.format(obs_col)\n",
    "        #interpret_ml(X_train_g, X_test_g, cols, model, shap_output_dir, exp_type)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a2ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE BY Year\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# split data for geographical division\n",
    "\n",
    "\n",
    "model_runs = [\"naive\",\"full\"]\n",
    "obs_columns=[\"rcsi_EAlevel\", \"rcsi_HHlevel\"]\n",
    "test_fraction=0.2\n",
    "\n",
    "#for test_fraction in [0.2]: #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "for model_type in model_runs: \n",
    "    if model_type=='full':\n",
    "        allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "           'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "           'lcgrass','lccrop', 'mzprice_yoy','mzprice', \n",
    "           'region', 'month']\n",
    "    else:\n",
    "        allVars=['region', 'month']\n",
    "    resp_cols = []\n",
    "    for var in allVars:\n",
    "        varcols=[col for col in rcsi_coll.columns if col.startswith(var)]\n",
    "        resp_cols.append(varcols)\n",
    "    resp_cols=list(chain(*resp_cols))\n",
    "    column_indices = [rcsi_coll.columns.get_loc(col) for col in resp_cols]\n",
    "    for obs_col in obs_columns: \n",
    "        exp_type = f'{obs_col}-wave-split-smote-{model_type}'\n",
    "        smote=SMOTE()\n",
    "        X_train = rcsi_coll.loc[rcsi_coll[\"wave\"] < 4, rcsi_coll.columns[column_indices]]\n",
    "        y_train = rcsi_coll.loc[rcsi_coll[\"wave\"] < 4, obs_col]\n",
    "        X_test_g = rcsi_coll.loc[rcsi_coll[\"wave\"]==4, rcsi_coll.columns[column_indices]]\n",
    "        y_test_g = rcsi_coll.loc[rcsi_coll[\"wave\"]==4, obs_col]\n",
    "        X_train_g, y_train_g = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        test_set = 'wave_4'\n",
    "\n",
    "        #X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "        #X_res, Y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "        cols = rcsi_coll.columns[column_indices]\n",
    "\n",
    "        # dataset stats\n",
    "\n",
    "        features_size = X_train_g.shape[1]\n",
    "        #irpl_train =  #Imbalance ratio per label\n",
    "        #label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "        #label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "        #using imbalance ratio per label for non-binary data\n",
    "        label_imb_train = class_irpl(y_train_g)\n",
    "        label_imb_test = class_irpl(y_test_g)\n",
    "        train_size = X_train_g.shape[0]\n",
    "        test_size = X_test_g.shape[0]\n",
    "\n",
    "        # feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_g = scaler.fit_transform(X_train_g)\n",
    "        X_test_g = scaler.transform(X_test_g)\n",
    "\n",
    "        # train model\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_g, y_train_g)\n",
    "        duration = time.time() - start_time\n",
    "        y_pred = model.predict(X_test_g)\n",
    "\n",
    "        # create confusion matrix\n",
    "        cm = confusion_matrix(y_test_g, y_pred)\n",
    "        cm\n",
    "\n",
    "        # compute all metrics\n",
    "        res = calculate_metrics_multiclass(res, y_test_g, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size)\n",
    "        #shap_output_dir = 'analysis_output/SHAP_mult_{}_smote'.format(obs_col)\n",
    "        #interpret_ml(X_train_g, X_test_g, cols, model, shap_output_dir, exp_type)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882378fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(\"rf_rcsi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c70e68",
   "metadata": {},
   "source": [
    "## Sequential Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "579b7cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-40 {color: black;}#sk-container-id-40 pre{padding: 0;}#sk-container-id-40 div.sk-toggleable {background-color: white;}#sk-container-id-40 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-40 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-40 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-40 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-40 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-40 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-40 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-40 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-40 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-40 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-40 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-40 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-40 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-40 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-40 div.sk-item {position: relative;z-index: 1;}#sk-container-id-40 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-40 div.sk-item::before, #sk-container-id-40 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-40 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-40 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-40 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-40 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-40 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-40 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-40 div.sk-label-container {text-align: center;}#sk-container-id-40 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-40 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-40\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SequentialFeatureSelector(direction=&#x27;backward&#x27;,\n",
       "                          estimator=RandomForestClassifier(), tol=-0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SequentialFeatureSelector</label><div class=\"sk-toggleable__content\"><pre>SequentialFeatureSelector(direction=&#x27;backward&#x27;,\n",
       "                          estimator=RandomForestClassifier(), tol=-0.001)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SequentialFeatureSelector(direction='backward',\n",
       "                          estimator=RandomForestClassifier(), tol=-0.001)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "       'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19',\n",
       "       'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28',\n",
       "       'x29', 'x30', 'x31', 'x32', 'x33', 'x34', 'x35', 'x36', 'x37',\n",
       "       'x38', 'x40', 'x41', 'x42', 'x43', 'x44', 'x45', 'x46', 'x47',\n",
       "       'x48', 'x49', 'x50', 'x51', 'x52', 'x53', 'x54', 'x55', 'x56',\n",
       "       'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63', 'x64', 'x65',\n",
       "       'x67', 'x68', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74', 'x75',\n",
       "       'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83', 'x84',\n",
       "       'x85', 'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x93',\n",
       "       'x94', 'x95', 'x96', 'x97', 'x98', 'x99', 'x100', 'x101', 'x102',\n",
       "       'x103', 'x104', 'x105', 'x106', 'x107', 'x108', 'x109', 'x110',\n",
       "       'x111', 'x112', 'x113', 'x114', 'x115', 'x116', 'x117', 'x118',\n",
       "       'x119', 'x120', 'x121', 'x122', 'x123', 'x124', 'x125', 'x126',\n",
       "       'x127'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# split data for geographical division\n",
    "\n",
    "\n",
    "model_runs = [\"full\"]\n",
    "obs_columns=[\"rcsi_HHlevel\"]\n",
    "test_fraction=0.2\n",
    "\n",
    "#for test_fraction in [0.2]: #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "for model_type in model_runs: \n",
    "    if model_type=='full':\n",
    "        allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "           'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "           'lcgrass','lccrop', 'mzprice_yoy','mzprice', \n",
    "           'region', 'month']\n",
    "    else:\n",
    "        allVars=['region', 'month']\n",
    "    resp_cols = []\n",
    "    for var in allVars:\n",
    "        varcols=[col for col in rcsi_coll.columns if col.startswith(var)]\n",
    "        resp_cols.append(varcols)\n",
    "    resp_cols=list(chain(*resp_cols))\n",
    "    column_indices = [rcsi_coll.columns.get_loc(col) for col in resp_cols]\n",
    "    for obs_col in obs_columns: \n",
    "        exp_type = f'{obs_col}-wave-split-smote-{model_type}'\n",
    "        smote=SMOTE()\n",
    "        X_train = rcsi_coll.loc[rcsi_coll[\"wave\"] < 4, rcsi_coll.columns[column_indices]]\n",
    "        y_train = rcsi_coll.loc[rcsi_coll[\"wave\"] < 4, obs_col]\n",
    "        X_test_g = rcsi_coll.loc[rcsi_coll[\"wave\"]==4, rcsi_coll.columns[column_indices]]\n",
    "        y_test_g = rcsi_coll.loc[rcsi_coll[\"wave\"]==4, obs_col]\n",
    "        X_train_g, y_train_g = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        test_set = 'wave_4'\n",
    "\n",
    "        #X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "        #X_res, Y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "        cols = rcsi_coll.columns[column_indices]\n",
    "\n",
    "        # dataset stats\n",
    "\n",
    "        features_size = X_train_g.shape[1]\n",
    "        #irpl_train =  #Imbalance ratio per label\n",
    "        #label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "        #label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "        #using imbalance ratio per label for non-binary data\n",
    "        label_imb_train = class_irpl(y_train_g)\n",
    "        label_imb_test = class_irpl(y_test_g)\n",
    "        train_size = X_train_g.shape[0]\n",
    "        test_size = X_test_g.shape[0]\n",
    "\n",
    "        # feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_g = scaler.fit_transform(X_train_g)\n",
    "        X_test_g = scaler.transform(X_test_g)\n",
    "\n",
    "        # train model\n",
    "        start_time = time.time()\n",
    "\n",
    "        sfs=SequentialFeatureSelector(model, direction='backward', tol=-0.001)\n",
    "        sfs.fit(X_train_g, y_train_g)\n",
    "        sfs.get_feature_names_out()\n",
    "        #duration = time.time() - start_time\n",
    "        #y_pred = model.predict(X_test_g)\n",
    "\n",
    "        # create confusion matrix\n",
    "        #cm = confusion_matrix(y_test_g, y_pred)\n",
    "        #cm\n",
    "\n",
    "        # compute all metrics\n",
    "        #res = calculate_metrics_multiclass(res, y_test_g, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size)\n",
    "        #shap_output_dir = 'analysis_output/SHAP_mult_{}_smote'.format(obs_col)\n",
    "        #interpret_ml(X_train_g, X_test_g, cols, model, shap_output_dir, exp_type)\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "94f16028",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequentialFeatureSelector' object has no attribute 'SelectFromModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelectFromModel\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SequentialFeatureSelector' object has no attribute 'SelectFromModel'"
     ]
    }
   ],
   "source": [
    "sfs.SelectFromModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d889c",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca32f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# split data for geographical division\n",
    "\n",
    "\n",
    "model_runs = [\"full\"]\n",
    "obs_columns=[\"rcsi_HHlevel\"]\n",
    "test_fraction=0.2\n",
    "\n",
    "#for test_fraction in [0.2]: #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "for model_type in model_runs: \n",
    "    if model_type=='full':\n",
    "        allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "           'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "           'lcgrass','lccrop', 'mzprice_yoy','mzprice', \n",
    "           'region', 'month']\n",
    "    else:\n",
    "        allVars=['region', 'month']\n",
    "    resp_cols = []\n",
    "    for var in allVars:\n",
    "        varcols=[col for col in rcsi_coll.columns if col.startswith(var)]\n",
    "        resp_cols.append(varcols)\n",
    "    resp_cols=list(chain(*resp_cols))\n",
    "    column_indices = [rcsi_coll.columns.get_loc(col) for col in resp_cols]\n",
    "    for obs_col in obs_columns: \n",
    "        exp_type = f'{obs_col}-wave-split-smote-{model_type}-tuned'\n",
    "        smote=SMOTE()\n",
    "        X_train = rcsi_coll.loc[rcsi_coll[\"wave\"] < 4, rcsi_coll.columns[column_indices]]\n",
    "        y_train = rcsi_coll.loc[rcsi_coll[\"wave\"] < 4, obs_col]\n",
    "        X_test_g = rcsi_coll.loc[rcsi_coll[\"wave\"]==4, rcsi_coll.columns[column_indices]]\n",
    "        y_test_g = rcsi_coll.loc[rcsi_coll[\"wave\"]==4, obs_col]\n",
    "        X_train_g, y_train_g = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        test_set = 'wave_4'\n",
    "\n",
    "        #X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "        #X_res, Y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "        cols = rcsi_coll.columns[column_indices]\n",
    "\n",
    "        # dataset stats\n",
    "\n",
    "        features_size = X_train_g.shape[1]\n",
    "        #irpl_train =  #Imbalance ratio per label\n",
    "        #label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "        #label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "        #using imbalance ratio per label for non-binary data\n",
    "        label_imb_train = class_irpl(y_train_g)\n",
    "        label_imb_test = class_irpl(y_test_g)\n",
    "        train_size = X_train_g.shape[0]\n",
    "        test_size = X_test_g.shape[0]\n",
    "\n",
    "        # feature Scaling\n",
    "        scaler = StandardScaler()\n",
    "        X_train_g = scaler.fit_transform(X_train_g)\n",
    "        X_test_g = scaler.transform(X_test_g)\n",
    "\n",
    "        # train model\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_g, y_train_g)\n",
    "        duration = time.time() - start_time\n",
    "        y_pred = model.predict(X_test_g)\n",
    "\n",
    "        # create confusion matrix\n",
    "        cm = confusion_matrix(y_test_g, y_pred)\n",
    "        cm\n",
    "\n",
    "        # compute all metrics\n",
    "        res = calculate_metrics_multiclass(res, y_test_g, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size)\n",
    "        #shap_output_dir = 'analysis_output/SHAP_mult_{}_smote'.format(obs_col)\n",
    "        #interpret_ml(X_train_g, X_test_g, cols, model, shap_output_dir, exp_type)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['logistic-regression', 'random-forest','tabnet']\n",
    "for model_name in model_names:\n",
    "\n",
    "    model = None\n",
    "\n",
    "    if model_name == 'logistic-regression':\n",
    "        model = LogisticRegression()\n",
    "\n",
    "    if model_name == 'random-forest':\n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "    if model_name == 'tabnet':\n",
    "        model = TabNetClassifier(verbose=0,seed=42)\n",
    "    model_runs = [\"naive\",\"full\"]\n",
    "    obs_columns=[\"rcsi_EAlevel\", \"rcsi_HHlevel\"]\n",
    "    test_fraction=0.2\n",
    "\n",
    "    #for test_fraction in [0.2]: #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    for model_type in model_runs: \n",
    "        if model_type=='full':\n",
    "            allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "               'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "               'lcgrass','lccrop', 'mzprice_yoy','mzprice', \n",
    "               'regionnum', 'month']\n",
    "        else:\n",
    "            allVars=['regionnum', 'month']\n",
    "        resp_cols = []\n",
    "        for var in allVars:\n",
    "            varcols=[col for col in rcsi_coll.columns if col.startswith(var)]\n",
    "            resp_cols.append(varcols)\n",
    "        resp_cols=list(chain(*resp_cols))\n",
    "        column_indices = [rcsi_coll.columns.get_loc(col) for col in resp_cols]\n",
    "        for obs_col in obs_columns: \n",
    "            exp_type = f'{obs_col}-wave-split-smote-{model_type}'\n",
    "            smote=SMOTE()\n",
    "            X_train = rcsi_coll.loc[rcsi_coll[\"wave\"] < 4, rcsi_coll.columns[column_indices]]\n",
    "            y_train = rcsi_coll.loc[rcsi_coll[\"wave\"] < 4, obs_col]\n",
    "            X_test_g = rcsi_coll.loc[rcsi_coll[\"wave\"]==4, rcsi_coll.columns[column_indices]]\n",
    "            y_test_g = rcsi_coll.loc[rcsi_coll[\"wave\"]==4, obs_col]\n",
    "            X_train_g, y_train_g = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "            test_set = 'wave_4'\n",
    "\n",
    "            #X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "            #X_res, Y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "            cols = rcsi_coll.columns[column_indices]\n",
    "\n",
    "            # dataset stats\n",
    "\n",
    "            features_size = X_train_g.shape[1]\n",
    "            #irpl_train =  #Imbalance ratio per label\n",
    "            #label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "            #label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "            #using imbalance ratio per label for non-binary data\n",
    "            label_imb_train = class_irpl(y_train_g)\n",
    "            label_imb_test = class_irpl(y_test_g)\n",
    "            train_size = X_train_g.shape[0]\n",
    "            test_size = X_test_g.shape[0]\n",
    "\n",
    "            # feature Scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_train_g = scaler.fit_transform(X_train_g)\n",
    "            X_test_g = scaler.transform(X_test_g)\n",
    "\n",
    "            # train model\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train_g, y_train_g)\n",
    "            duration = time.time() - start_time\n",
    "            y_pred = model.predict(X_test_g)\n",
    "\n",
    "            # create confusion matrix\n",
    "            cm = confusion_matrix(y_test_g, y_pred)\n",
    "            cm\n",
    "\n",
    "            # compute all metrics\n",
    "            res = calculate_metrics_multiclass(res, y_test_g, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size)\n",
    "            #shap_output_dir = "analysis_output/SHAP_mult_{}_smote'.format(obs_col)\n",
    "            #interpret_ml(X_train_g, X_test_g, cols, model, shap_output_dir, exp_type)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb387db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['logistic-regression', 'random-forest','tabnet']\n",
    "for model_name in model_names:\n",
    "\n",
    "    model = None\n",
    "\n",
    "    if model_name == 'logistic-regression':\n",
    "        model = LogisticRegression()\n",
    "\n",
    "    if model_name == 'random-forest':\n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "    if model_name == 'tabnet':\n",
    "        model = TabNetClassifier(verbose=0,seed=42)\n",
    "    model_runs = [\"naive\",\"full\"]\n",
    "    obs_columns=[\"rcsi_EAlevel\", \"rcsi_HHlevel\"]\n",
    "    test_fraction=0.2\n",
    "\n",
    "    #for test_fraction in [0.2]: #[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "    for model_type in model_runs: \n",
    "        if model_type=='full':\n",
    "            allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "               'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "               'lcgrass','lccrop', 'mzprice_yoy','mzprice', \n",
    "               'regionnum', 'month', 'nightlights']\n",
    "        else:\n",
    "            allVars=['regionnum', 'month']\n",
    "        resp_cols = []\n",
    "        for var in allVars:\n",
    "            varcols=[col for col in rcsi_coll.columns if col.startswith(var)]\n",
    "            resp_cols.append(varcols)\n",
    "        resp_cols=list(chain(*resp_cols))\n",
    "        column_indices = [rcsi_coll.columns.get_loc(col) for col in resp_cols]\n",
    "        for obs_col in obs_columns: \n",
    "            exp_type = f'{obs_col}-wave-split-smote-nightlights-{model_type}'\n",
    "            #smote=SMOTE()\n",
    "            X_train_g = rcsi_coll.dropna().loc[(rcsi_coll[\"wave\"] < 4) & (rcsi_coll[\"wave\"]>1), rcsi_coll.columns[column_indices]]\n",
    "            y_train_g = rcsi_coll.dropna().loc[(rcsi_coll[\"wave\"] < 4) & (rcsi_coll[\"wave\"]>1), obs_col]\n",
    "            X_test_g = rcsi_coll.dropna().loc[rcsi_coll[\"wave\"]==4, rcsi_coll.columns[column_indices]]\n",
    "            y_test_g = rcsi_coll.dropna().loc[rcsi_coll[\"wave\"]==4, obs_col]\n",
    "            #X_train_g, y_train_g = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "            test_set = 'wave_4'\n",
    "\n",
    "            #X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "            #X_res, Y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "            cols = rcsi_coll.columns[column_indices]\n",
    "\n",
    "            # dataset stats\n",
    "\n",
    "            features_size = X_train_g.shape[1]\n",
    "            #irpl_train =  #Imbalance ratio per label\n",
    "            #label_imb_train = y_train_g.sum()/len(y_train_g)\n",
    "            #label_imb_test = y_test_g.sum()/len(y_test_g)\n",
    "            #using imbalance ratio per label for non-binary data\n",
    "            label_imb_train = class_irpl(y_train_g)\n",
    "            label_imb_test = class_irpl(y_test_g)\n",
    "            train_size = X_train_g.shape[0]\n",
    "            test_size = X_test_g.shape[0]\n",
    "\n",
    "            # feature Scaling\n",
    "            scaler = StandardScaler()\n",
    "            X_train_g = scaler.fit_transform(X_train_g)\n",
    "            X_test_g = scaler.transform(X_test_g)\n",
    "\n",
    "            # train model\n",
    "            start_time = time.time()\n",
    "            model.fit(X_train_g, y_train_g)\n",
    "            duration = time.time() - start_time\n",
    "            y_pred = model.predict(X_test_g)\n",
    "\n",
    "            # create confusion matrix\n",
    "            cm = confusion_matrix(y_test_g, y_pred)\n",
    "            cm\n",
    "\n",
    "            # compute all metrics\n",
    "            res = calculate_metrics_multiclass(res, y_test_g, y_pred, duration, exp_type, test_set, model_name, features_size, label_imb_train, label_imb_test, train_size, test_size)\n",
    "            #shap_output_dir = 'analysis_output/SHAP_mult_{}_smote'.format(obs_col)\n",
    "            #interpret_ml(X_train_g, X_test_g, cols, model, shap_output_dir, exp_type)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24ff70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.157953945431913"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "#months = ['jan', 'feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "#monthnums = pd.DataFrame({\"month\": months, \"monthnum\": [9,10,11,0,1,2,3,4,5,6,7,8]})\n",
    "from random import sample\n",
    "from itertools import chain\n",
    "\n",
    "model=LassoCV()\n",
    "model_runs = [\"naive\",\"full\"]\n",
    "obs_col='rcsi_EAavgscore'\n",
    "\n",
    "for model_type in model_runs: \n",
    "    if model_type=='full':\n",
    "        allVars = ['ndvi', 'pdsi', 'ppt', 'soil', 'vap', 'vpd', \n",
    "           'tmin', 'tmax', 'tmean', 'lcurb', 'lcforst', \n",
    "           'lcgrass','lccrop', 'mzprice_yoy','mzprice', \n",
    "           'region', 'offset']\n",
    "    else:\n",
    "        allVars=['region', 'offset']\n",
    "    resp_cols = []\n",
    "    for var in allVars:\n",
    "        varcols=[col for col in rcsi_coll.columns if col.startswith(var)]\n",
    "        resp_cols.append(varcols)\n",
    "    resp_cols=list(chain(*resp_cols))\n",
    "    column_indices = [rcsi_coll.columns.get_loc(col) for col in resp_cols]\n",
    "\n",
    "    \n",
    "    exp_type = f'{obs_col}-wave-split-smote-nightlights-{model_type}'\n",
    "    #smote=SMOTE()\n",
    "    X_train_g = rcsi_coll.dropna().loc[(rcsi_coll[\"wave\"] < 4) & (rcsi_coll[\"wave\"]>1), rcsi_coll.columns[column_indices]]\n",
    "    y_train_g = rcsi_coll.dropna().loc[(rcsi_coll[\"wave\"] < 4) & (rcsi_coll[\"wave\"]>1), obs_col]\n",
    "    X_test_g = rcsi_coll.dropna().loc[rcsi_coll[\"wave\"]==4, rcsi_coll.columns[column_indices]]\n",
    "    y_test_g = rcsi_coll.dropna().loc[rcsi_coll[\"wave\"]==4, obs_col]\n",
    "    #X_train_g, y_train_g = smote.fit_resample(X_train, y_train)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_g = scaler.fit_transform(X_train_g)\n",
    "    X_test_g = scaler.transform(X_test_g)\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_g, y_train_g)\n",
    "    duration = time.time() - start_time\n",
    "    model.score(X_train_g,y_train_g)\n",
    "    y_pred = model.predict(X_test_g)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae76a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = pd.DataFrame({\"y_obs\": y_test_g, \"y_pred\": y_pred}).reset_index(drop=True)\n",
    "comps.to_csv(\"RCSI/rcsi_lasso.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a94e9b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       3.437500\n",
       "3       8.687500\n",
       "6       7.750000\n",
       "8       6.500000\n",
       "9       7.375000\n",
       "          ...   \n",
       "2439    2.625000\n",
       "2443    3.375000\n",
       "2445    5.250000\n",
       "2447    3.846154\n",
       "2448    4.625000\n",
       "Name: rcsi_EAavgscore, Length: 879, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
